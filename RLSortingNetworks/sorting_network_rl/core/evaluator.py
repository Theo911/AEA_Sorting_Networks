import os
import logging
import csv
import torch
import numpy as np
from typing import Dict, Any, List, Tuple, Optional

from RLSortingNetworks.sorting_network_rl.env.sorting_env import SortingNetworkEnv
from RLSortingNetworks.sorting_network_rl.agent.dqn_agent import DQNAgent
from RLSortingNetworks.sorting_network_rl.utils.state_encoder import encode_state
from RLSortingNetworks.sorting_network_rl.utils.evaluation import is_sorting_network, prune_redundant_comparators, format_network_visualization
from RLSortingNetworks.sorting_network_rl.utils.config_loader import load_config

logger = logging.getLogger(__name__)

class Evaluator:
    """Handles evaluation of a trained DQN agent's policy."""

    def __init__(self, config: Dict[str, Any], model_path: str):
        """Initializes the Evaluator.

        Args:
            config (Dict[str, Any]): The configuration dictionary used for training.
            model_path (str): Path to the saved model (.pt file) to evaluate.
        """
        self.config = config
        self.env_cfg = config['environment']
        self.model_path = model_path

        logger.info(f"Initializing evaluator for model: {model_path}")
        logger.info(f"Using environment config: n_wires={self.env_cfg['n_wires']}, max_steps={self.env_cfg['max_steps']}")

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")

        # --- Setup Environment and Agent (for evaluation) ---
        self.env = SortingNetworkEnv(n_wires=self.env_cfg['n_wires'], max_steps=self.env_cfg['max_steps'])
        self.state_dim = encode_state(self.env.n_wires, self.env.max_steps, []).shape[0]
        self.action_dim = self.env.get_action_space_size()

        # Create agent with dummy learning params, load the trained model
        # Pass the original config for model architecture consistency
        self.agent = DQNAgent(self.state_dim, self.action_dim, config)
        try:
            self.agent.load_model(self.model_path)
            # Set agent to evaluation mode
            self.agent.policy_net.eval()
            self.agent.epsilon = 0.0 # No exploration during evaluation
            logger.info("Agent model loaded and set to evaluation mode (epsilon=0).")
        except (FileNotFoundError, IOError) as e:
            logger.error(f"Failed to load model for evaluation: {e}")
            raise # Re-raise the exception

    def evaluate_policy(self) -> Tuple[Optional[List[Tuple[int, int]]], bool]:
        """Runs the agent's learned policy for one episode to generate a network.

        Returns:
            Tuple[Optional[List[Tuple[int, int]]], bool]:
                - The list of comparators generated by the policy, or None if error.
                - A boolean indicating if the generated network is a valid sorting network.
        """
        logger.info("Evaluating agent policy...")
        state_info = self.env.reset()
        done = False
        comparators_generated: List[Tuple[int, int]] = []

        try:
            with torch.no_grad(): # Disable gradient calculations
                while not done:
                    state_vector = encode_state(self.env.n_wires, self.env.max_steps, state_info['comparators'])
                    # Epsilon is 0, agent selects greedily
                    action = self.agent.select_action(state_vector)

                    next_state_info, _, env_done = self.env.step(action)
                    state_info = next_state_info
                    comparators_generated = state_info['comparators'] # Update list

                    # Check termination (max steps reached)
                    if env_done:
                        done = True

            # Check if the generated network is valid
            is_valid = is_sorting_network(self.env.n_wires, comparators_generated)
            valid_str = "VALID" if is_valid else "INVALID"
            logger.info(f"Evaluation finished. Generated network length: {len(comparators_generated)}. Status: {valid_str}")

            return comparators_generated, is_valid

        except Exception as e:
            logger.error(f"An error occurred during policy evaluation: {e}", exc_info=True)
            return None, False

    def load_network_from_csv(self, csv_path: str) -> Optional[List[Tuple[int, int]]]:
        """Loads a network saved in a CSV file (e.g., best_network.csv)."""
        if not os.path.exists(csv_path):
            logger.warning(f"Network CSV file not found: {csv_path}")
            return None
        try:
            comparators = []
            with open(csv_path, 'r') as f:
                reader = csv.reader(f)
                next(reader) # Skip header line
                for row in reader:
                    if len(row) == 2:
                        try:
                            comparators.append((int(row[0]), int(row[1])))
                        except ValueError:
                            logger.warning(f"Skipping invalid row in {csv_path}: {row}")
                    else:
                         logger.warning(f"Skipping row with incorrect format in {csv_path}: {row}")
            logger.info(f"Loaded network with {len(comparators)} comparators from {csv_path}")
            return comparators
        except Exception as e:
            logger.error(f"Error reading network CSV file {csv_path}: {e}")
            return None